{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Jenkins shared library project Welcome to the Jenkins shared library project Purpose Quickstart About quality Useful links Purpose providing a reference example project for your own Jenkins shared library project demonstrating usage of the basic toolset: Groovy, Gradle, Jacoco, Codenarc, mkdocs, ... providing Jenkinsfile (declarative pipeline) as well as .travis.yml automatically running this project on Travis CI and publishing coverage on coveralls.io providing detailed documentation Quickstart Using the Gradle wrapper the configured Gradle version will be automatically downloaded and used. The basic requirements can be easily seen in the file Dockerfile serving as description for a Docker build image. ./gradlew About quality You should have a verified code style. The tool Codenarc provides you for Groovy what Checkstyle does for Java. The build does fail when any source code does not match the defined rules. It runs automatically with ./gradlew . Code coverage check is configured and 100% code coverage (line) is expected ! If you add new functionality without a test the build will fail. It also runs automatically with ./gradlew . Provide reasonable documentation . Any documentation like this one is for you as well as for others. Please consider source code documentation as well as markdown based documentation to help to understand things. Useful links https://jenkins.io/doc/book/pipeline/syntax/ https://jenkins.io/doc/pipeline/steps/pipeline-utility-steps/ https://jenkins.io/doc/book/pipeline/syntax/#declarative-pipeline https://jenkins.io/doc/book/pipeline/docker/ https://jenkins.io/doc/pipeline/steps/ https://gradle.org/ https://docs.gradle.org/current/userguide/jacoco_plugin.html https://gradle-pitest-plugin.solidsoft.info/ http://pitest.org/ http://codenarc.sourceforge.net/ https://www.mkdocs.org/","title":"Home"},{"location":"documentation/","text":"How to organize Documenation Markdown Markdown seems a good choice when writing documentation with just a small set of formatting capabilities reducing the documentation to what is really needed: titles sections bold and italic emphasizing code blocks tables links embedded images Mkdocs There are many good tools but I feel very comfortable with mkdocs because of following reasons: Easy to install ( sudo pip install mkdocs ) Easy to configure (Small and simple mkdocs.yml in the root of your repository) Easy to verify of the final result ( mkdocs serve ) Each change of the configured markdown files updates automatically your browser Easy to publish to github pages ( mkdocs gh-deploy ) In my case: simply my user and password for my Github account Please note: There's also a plugin for gradle but it looks to me that the excepted folder struture is different and I have not yet found a way to use the exising folder structure.","title":"How to organize Documenation"},{"location":"documentation/#how-to-organize-documenation","text":"","title":"How to organize Documenation"},{"location":"documentation/#markdown","text":"Markdown seems a good choice when writing documentation with just a small set of formatting capabilities reducing the documentation to what is really needed: titles sections bold and italic emphasizing code blocks tables links embedded images","title":"Markdown"},{"location":"documentation/#mkdocs","text":"There are many good tools but I feel very comfortable with mkdocs because of following reasons: Easy to install ( sudo pip install mkdocs ) Easy to configure (Small and simple mkdocs.yml in the root of your repository) Easy to verify of the final result ( mkdocs serve ) Each change of the configured markdown files updates automatically your browser Easy to publish to github pages ( mkdocs gh-deploy ) In my case: simply my user and password for my Github account Please note: There's also a plugin for gradle but it looks to me that the excepted folder struture is different and I have not yet found a way to use the exising folder structure.","title":"Mkdocs"},{"location":"gradle/","text":"How to organize Gradle How to organize Gradle Why Gradle? The Gradle Wrapper Current Gradle version Adding a wrapper Upgrading the Gradle version Basic Setup Best Practises Why Gradle? Gradle is very comfortable task manager to build your project. You can define the required tasks with a short amount of code . The Gradle Wrapper The gradle wrapper helps you to install the Gradle version you need. Current Gradle version ./gradlew --version Adding a wrapper gradle wrapper Upgrading the Gradle version Define the version of Gradle you would like to have: ./gradlew wrapper --gradle-version 4.9 You can verify it like following: $ cat gradle/wrapper/gradle-wrapper.properties distributionBase=GRADLE_USER_HOME distributionPath=wrapper/dists distributionUrl=https\\://services.gradle.org/distributions/gradle-4.9-bin.zip zipStoreBase=GRADLE_USER_HOME zipStorePath=wrapper/dists Basic Setup Of course it requires apply plugin: 'groovy' because the shared library (Jenkins) depends on it. The source sets have to be changed because the Jenkins guys do not use the standard folder structure as proposed by Maven/Gradle. The name of the languages (here: groovy) has been removed from the paths. You are not advised to use vars in the source sets because you cannot test the code and you code coverage would essentially decrease. Jacoco is used as official documented. Code coverage should be above 85% (line coverage 100%). Adding new functionality without adding sufficient tests should fail the build. Codenarc is the static code analyser for Groovy. Most rules are used and located under config/codenarc/codenarc.rules . Every rule that is not correct applied will fail the build. Coveralls (a great service for visualizing code coverage results) is useful if you run your Github project with integrations like Travis CI - In both cases you have to enable the repository there before you can use it; in my case login with my Github Account to Travis CI as well as to COVERALLS ; it's mainly a button to toggle the wanted repository on/off. Best Practises When one of your tests is failing Gradle usually prints the path to the XML file instead of showing the problem. Therefor you can do following: gradle test -i ; the -i forces to print all to stdout and that way you can easily scroll back the terminal to the printed callstack. Continous testing can be done with gradle test -it . Gradle detects changes in files when you save them and reruns the tasks (here: all tests). You also can run individual tests with a filter: gradle test -it --tests GradleTest","title":"How to organize Gradle"},{"location":"jobdslcode/","text":"Job DSL code support Job DSL code support Purpose Job definition Example with JSON Example with YAML Purpose Job DSL is great Jenkins pluging offering you an API for creating and/or updating of Jenkins jobs and views. This library adds now functionality to read a job description via Map (in Memory), a JSON file or a YAML file generating Job DSL code. Job definition Independent whether you use a Map in memory, a JSON file or a yaml file the job definition for creating a new job is following: field meaning comment name name of the job an existing job with will be update if it is of same type description job description also may contain HTML; rendered when configured in Jenkins type type of job supported: MULTIBRANCH_PIPELINE (default) or PIPELINE source source url git is supported only (ssh or https variant of url to clone) credentialsId Id of credentials optional ; Jenkins credentials store for SSH credentials script Jenkinsfile path path and filename of Jenkinsfile (default: Jenkinsfile) history number of builds pipeline only ; how many old builds to keep (default: 30) libraries list of libraries defines shared libraries for multibranch jobs A library entry is again a map: field meaning comment name name of the library The name to specify with @Library defaultVersion branch or tag if not specified: master credentialsId id for access refers to Jenkins credential store; optional url git url url of source code repository (https, ssh, ...) Example with JSON @Library('jenkins-shared-library@master') import groovy.json.JsonOutput pipeline { agent any stages { stage('Prepare') { steps { script { final DATA = readJSON(text:groovy.json.JsonOutput.toJson([ type:'MULTIBRANCH_PIPELINE', name:'jenkins-shared-library-demo', description:'a Jenkins shared library', source:'https://github.com/Nachtfeuer/jenkins-shared-library.git', script:'Jenkinsfile', libraries: [[ name:'jenkins-shared-library', url:'https://github.com/Nachtfeuer/jenkins-shared-library.git' ]] ])) writeJSON(file:'demo.json', json:DATA) } } } stage('Job DSL') { steps { script { jobDsl(scriptText:jobDslCode.fromJson('demo.json')) } } } } } Example with YAML @Library('jenkins-shared-library@master') pipeline { agent any stages { stage('Prepare') { steps { script { final DATA = [ type:'MULTIBRANCH_PIPELINE', name:'jenkins-shared-library-demo', description:'a Jenkins shared library', source:'https://github.com/Nachtfeuer/jenkins-shared-library.git', script:'Jenkinsfile', libraries: [[ name:'jenkins-shared-library', url:'https://github.com/Nachtfeuer/jenkins-shared-library.git' ]] ] writeYaml(file:'demo.yaml', data:DATA) } } } stage('Job DSL') { steps { script { jobDsl(scriptText:jobDslCode.fromYaml('demo.yaml')) } } } } }","title":"Job DSL code support"},{"location":"virtualenv/","text":"Python virtual environments Python virtual environments Most simple usage Passing requirements Defining another virtual environment folder Error handling Most simple usage virtualenv { sh(script:'python -m install spline') sh(script:'python -m spline.application --help') } Passing requirements virtualenv(['spline', 'requests==2.12.4']) { sh(script:'python -m spline.application --help') } Defining another virtual environment folder virtualenv(['spline', 'requests==2.12.4'], 'another-venv') { sh(script:'python -m spline.application --help') } Error handling When inside a virtual environment an exception is thrown: the result of such a block is null . the pipeline state (currentBuild.result) will be set to 'FAILURE'. the virtual environment will be removed independent of that issue.","title":"Python virtual environments"},{"location":"xdup/","text":"Duplicate Code Finder Introduction In fact the tool does not know about code but text. Following options are available: (m)inimum(B)lockSize : When duplicate code/test has been found it has to be greater or equal to those configured size otherwise it will be ignored. (default: 4) (i)gnore(C)ase : when true then the letter case is ignored (default: false) (i)gnore(W)hitespaces : when true then spaces and tabs are ignored (default: false) (p)ercentage(S)imilarity : control how many characters have to match (in percentage) The next table should give a few simple examples on line comparisons: First String Second String Adjusted Policies Result wonderful day wonderful day equal wonderful DAY wonderful day not equal wonderful DAY wonderful day iC=true equal wonderful DAY wo nd erful d ay iC=true not equal wonderful DAY wo nd erful d ay iC=true, iW=true equal Wonderful Day wonderful day pS=75 equal -onderful -ay wonderful day pS=75 equal Usage def listOfSource = xfind.files('.', '*.groovy') xdup(listOfSources, minimumBlockSize:6, ignoreCase:true, ignoreWhitespaces:true, percentageSimilarity:90) Please note : In a declarative pipeline you have to place it in a script { ... } block.","title":"Duplicate Code Finder"},{"location":"xdup/#duplicate-code-finder","text":"","title":"Duplicate Code Finder"},{"location":"xdup/#introduction","text":"In fact the tool does not know about code but text. Following options are available: (m)inimum(B)lockSize : When duplicate code/test has been found it has to be greater or equal to those configured size otherwise it will be ignored. (default: 4) (i)gnore(C)ase : when true then the letter case is ignored (default: false) (i)gnore(W)hitespaces : when true then spaces and tabs are ignored (default: false) (p)ercentage(S)imilarity : control how many characters have to match (in percentage) The next table should give a few simple examples on line comparisons: First String Second String Adjusted Policies Result wonderful day wonderful day equal wonderful DAY wonderful day not equal wonderful DAY wonderful day iC=true equal wonderful DAY wo nd erful d ay iC=true not equal wonderful DAY wo nd erful d ay iC=true, iW=true equal Wonderful Day wonderful day pS=75 equal -onderful -ay wonderful day pS=75 equal","title":"Introduction"},{"location":"xdup/#usage","text":"def listOfSource = xfind.files('.', '*.groovy') xdup(listOfSources, minimumBlockSize:6, ignoreCase:true, ignoreWhitespaces:true, percentageSimilarity:90) Please note : In a declarative pipeline you have to place it in a script { ... } block.","title":"Usage"},{"location":"xfind/","text":"Find DSL How to use? def files = xfind.files('.', '*.json') The command is equivalent to find . -type f -name \"*.json\" . Please note : - In a declarative pipeline you have to place it in a script { ... } block.","title":"Find DSL"},{"location":"xfind/#find-dsl","text":"","title":"Find DSL"},{"location":"xfind/#how-to-use","text":"def files = xfind.files('.', '*.json') The command is equivalent to find . -type f -name \"*.json\" . Please note : - In a declarative pipeline you have to place it in a script { ... } block.","title":"How to use?"},{"location":"xgit/","text":"Git DSL Git DSL Usage Example pipeline Usage echo('Git short commit: ' + xgit.shortCommit) echo('Git url: ' + xgit.url) echo('Git author name: ' + xgit.authorName) echo('Git author mail: ' + xgit.authorMail) echo('Git last tag: ' + xgit.lastTag) echo('Git changes since last tag: ' + xgit.changesSinceLastTag) Please note : - In a declarative pipeline you have to place it in a script { ... } block. Example pipeline The pipeline show here does not build anything; it's just the focus on Git and versioning. The choosen model is semantic versioning means we do not write a version into a pom.xml or a build.gradle (or any other build file). The latest version is fetch from last tag; if you don't have a tag yet the version specified by define is taken. In given example the branch master is defined as only release branch; for all other branch we specify the version as snapshot. For the release branch we do tagging only. Tagging will be disabled if there is no change detected since last tag. @Library('jenkins-shared-library@master') _ def currentVersion = [:] def taggingEnabled = false pipeline { agent any options { buildDiscarder(logRotator(numToKeepStr: '10')) disableConcurrentBuilds() timestamps() ansiColor('xterm') timeout(time: 10, unit: 'MINUTES') } stages { stage('Prepare') { steps { script { // defines your version policy (default here: major.minor) currentVersion = xversion.define() // trying to get current version from (last) tag currentVersion = xversion.get(tag:currentVersion) // master branch is release here; all other branches are snapshots currentVersion.meta.snapshot = !env.BRANCH_NAME.equals('master') def hasChanges = xgit.changesSinceLastTag def description = b commit /b : ${xgit.shortCommit}, b lastAuthor /b : ${xgit.authorName} if (!hasChanges) { description = description + br/ No changes! } currentBuild.description = description // release branch (here: master) increments only if (env.BRANCH_NAME.equals('master') hasChanges) { currentVersion = xversion.increment(minor:currentVersion) taggingEnabled = true } currentBuild.displayName = '#' + env.BUILD_NUMBER + ' - ' + xversion.stringifyForTag(currentVersion) } } } } post { success { script { if ('master'.equals(env.BRANCH_NAME) taggingEnabled) { sshagent(['SSH_GIT_CREDENTIALS']) { xversion.apply(tag:currentVersion) } } } } } }","title":"Git DSL"},{"location":"xgradle/","text":"Own Gradle DSL Purpose builder concept (chaining of tasks) standardization (junit, jacoco, ...) Build The xgradle DSL does use internally a Gradle class chaining the tasks clean and check : xgradle.build() Please note : In a declarative pipeline you have to place it in a script { ... } block. Publish Publishing of build results (junit, jacoco, HTML coverage and Pit test coverage): xgradle.publish() Please note : - In a declarative pipeline you have to place it in a script { ... } block. - The reports are published only when the path do exist; for coverage build/reports/coverage and for pit test build/reports/pitest are the expected paths. Using Jacoco you can configure it with html.destination file(\"${buildDir}/reports/coverage\") . You can check the file build.gradle of this project.","title":"Own Gradle DSL"},{"location":"xgradle/#own-gradle-dsl","text":"","title":"Own Gradle DSL"},{"location":"xgradle/#purpose","text":"builder concept (chaining of tasks) standardization (junit, jacoco, ...)","title":"Purpose"},{"location":"xgradle/#build","text":"The xgradle DSL does use internally a Gradle class chaining the tasks clean and check : xgradle.build() Please note : In a declarative pipeline you have to place it in a script { ... } block.","title":"Build"},{"location":"xgradle/#publish","text":"Publishing of build results (junit, jacoco, HTML coverage and Pit test coverage): xgradle.publish() Please note : - In a declarative pipeline you have to place it in a script { ... } block. - The reports are published only when the path do exist; for coverage build/reports/coverage and for pit test build/reports/pitest are the expected paths. Using Jacoco you can configure it with html.destination file(\"${buildDir}/reports/coverage\") . You can check the file build.gradle of this project.","title":"Publish"},{"location":"xlocal/","text":"Use of the library without Jenkins Use of the library without Jenkins Introduction Simple scenario Using the fat jar as tool Supported DSL functions Is vars dead code? Introduction Writing Jenkins DSL code usually also means to write unittests and to mock things because you don't have the Jenkins and its plugins as part of your build process (and you also should not have it). However there are usecases where it would be awesome when you were able to use your own library code locally (still: without Jenkins): testing your library code that it does work as expected (without mocks). using your library as a tool to run a Jenkinsfile without Jenkins. The first use case is more simple since you - usually - don't require too many DSL functions that have to be implemented before you can test one or two of your classes. For the second use case you require quite some DSL because you have to implement all DSL you see in a Jenkinsfile and the few DSL functions used in the classes. Giving you an idea see next section ... Simple scenario Consider the duplicate code DSL and the related classes in this library. That library code does required sh , readFile and writeFile as DSL functions. The class my.dsl.Jenkinks does implement all this DSL functions for local use while the class my.dsl.ScriptExecutor is capable of running any Groovy code: import my.dsl.Jenkins import my.dsl.ScriptExecutor def executor = new ScriptExecutor(Jenkins) executor.execute(''' import my.tools.DuplicateCodeFinder import my.tools.Find def sourceFiles = new Find(this).files('src', '*.groovy') sourceFiles.addAll(new Find(this).files('test', '*.groovy')) def dup = new DuplicateCodeFinder(this) dup.minimumBlockSize = 8 dup.sourceFiles = sourceFiles dup.check() ''') println('done') Being in the root of this project call it like following: groovy -cp src examples/xdup.groovy It works really good. Even the my.dsl.* code can be easily unittested. At the end you just need one all in one jar being executable to pass a script file as parameter which works similar to the example above. Using the fat jar as tool $ java -jar build/libs/jenkins-shared-pipeline-all-1.0.jar --help usage: java -jar jenkins-shared-pipeline.jar [options] Options: -h,--help Print this help text and exit. -s,--script file Groovy script file If you put the code passed to the ScriptExecutor in last example into a file you can do following $ java -jar build/libs/jenkins-shared-pipeline-all-1.0.jar --script /tmp/xdup.groovy Supported DSL functions It will constantly be extended but for now following DSL functions are implemented: Commands: echo sh writeFile readFile withEnv stage xparser xfind xpublish xgit xgradle xrender xversion virtualenv xdup Please note : The DSL xpublish does not do anything locally. Is vars dead code? At least I have not found a way (yet) how to use it without Jenkins. The ScriptExecutor expects an abstract class that implements those DSL code for injecting it into a GroovyShell instance. The mechanism basically comes from Groovy itself. Compiling the sources in vars (which is possible) I need to find a way how those scripts know the DSL they use. Because of this and the problem that the code cannot easily be tested (yet) you should keep the code of your own DSL functions very vey small delegating to a class based implementation using dependency injection under src/** .","title":"Use of the library without Jenkins"},{"location":"xparser/","text":"Parser Parsing XML Converts XML document into Groovy object model. def document = xparser.xml(readFile(file:'pom.xml'))","title":"Parser"},{"location":"xparser/#parser","text":"","title":"Parser"},{"location":"xparser/#parsing-xml","text":"Converts XML document into Groovy object model. def document = xparser.xml(readFile(file:'pom.xml'))","title":"Parsing XML"},{"location":"xpublish/","text":"The publisher Publishing HTML Reports xpublish.html('HTML Code Coverage', 'build/reports/coverage') Please note : Using a declarative pipeline you have to call it inside a script { ... } block.","title":"The publisher"},{"location":"xpublish/#the-publisher","text":"","title":"The publisher"},{"location":"xpublish/#publishing-html-reports","text":"xpublish.html('HTML Code Coverage', 'build/reports/coverage') Please note : Using a declarative pipeline you have to call it inside a script { ... } block.","title":"Publishing HTML Reports"},{"location":"xversion/","text":"Versioning and Tagging Versioning and Tagging Versioning Defining your version Version as string Increment the version Retrieving current version Applying version to tool Versioning Defining your version First you define your version giving the individual parts a name; the names are your personal choice. The numbers are the initial version when there is no version yet. def version = xversion.define(major:1, minor:0, patch:0) println(version) // prints [data:[major:1, minor:0, patch:0], meta:[snapshot:false, prefix:'v']] or using major and minor as default policy: def version = xversion.define() println(version) // prints [data:[major:1, minor:0], meta:[snapshot:false, prefix:'v']] Version as string If the version.meta.snapshot is true then stringify appends `-SNAPSHOT' ( stringifyForTag does not): def version = xversion.define() println(xversion.stringify(version)) // prints '1.0' println(xversion.stringifyForTag(version)) // prints 'v1.0' Increment the version The incrementor - as the name says - increments a version part. def version = xversion.define(major:1, minor:0, patch:0) version = xversion.increment(major:version) println(version) // prints [data:[major:2, minor:0, patch:0], meta:[snapshot:false, prefix,'v']] or def version = xversion.define(major:2, minor:0, patch:0) version = xversion.increment(minor:version) println(version) // prints [data:[major:2, minor:1, patch:0], meta:[snapshot:false, prefix,'v']] Retrieving current version You can retrieve the version either by the underyling build tools or using last tag. When there is not tag the defined version is used. It's expected that existing version match the version policy otherwise an exception is thrown. def version = xversion.get(maven:version) // reading from pom.xml def version = xversion.get(gradle:version) // reading from build.gradle def version = xversion.get(tag:version) // reading from tag Applying version to tool It does change the version either in the pom.xml or in the build.gradle : xversion.apply(maven:version) // adjusts the pom.xml xversion.apply(gradle:version) // adjusts the version field in the build.gradle xversion.apply(tag:version) // creates and pushes version as tag","title":"Versioning and Tagging"}]}